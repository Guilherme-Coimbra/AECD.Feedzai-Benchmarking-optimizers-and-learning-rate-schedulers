{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1524c8e7",
   "metadata": {},
   "source": [
    "# Preparation of data\n",
    "\n",
    "Here we will procede to prepare the data to be fed into our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f98b68",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7baddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.api.types as pdt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib \n",
    "\n",
    "from src import paths, utils\n",
    "from src.io_ops import read_csv_safely\n",
    "\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f6dd7",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b9d84ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fraud_bool', 'income', 'name_email_similarity',\n",
       "       'prev_address_months_count', 'current_address_months_count',\n",
       "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
       "       'payment_type', 'zip_count_4w', 'velocity_6h', 'velocity_24h',\n",
       "       'velocity_4w', 'bank_branch_count_8w',\n",
       "       'date_of_birth_distinct_emails_4w', 'employment_status',\n",
       "       'credit_risk_score', 'email_is_free', 'housing_status',\n",
       "       'phone_home_valid', 'phone_mobile_valid', 'bank_months_count',\n",
       "       'has_other_cards', 'proposed_credit_limit', 'foreign_request', 'source',\n",
       "       'session_length_in_minutes', 'device_os', 'keep_alive_session',\n",
       "       'device_distinct_emails_8w', 'device_fraud_count', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = paths.RAW_DATA_DIR / \"Base.csv\"\n",
    "\n",
    "df_base = read_csv_safely(BASE_PATH)\n",
    "df_base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30ad5c",
   "metadata": {},
   "source": [
    "## Remove unwanted columns\n",
    "\n",
    "As we checked in notebook 01 columns \"device_fraud_count\" is constant and so irrelevant for our model. We will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea8e785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fraud_bool', 'income', 'name_email_similarity',\n",
       "       'prev_address_months_count', 'current_address_months_count',\n",
       "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
       "       'payment_type', 'zip_count_4w', 'velocity_6h', 'velocity_24h',\n",
       "       'velocity_4w', 'bank_branch_count_8w',\n",
       "       'date_of_birth_distinct_emails_4w', 'employment_status',\n",
       "       'credit_risk_score', 'email_is_free', 'housing_status',\n",
       "       'phone_home_valid', 'phone_mobile_valid', 'bank_months_count',\n",
       "       'has_other_cards', 'proposed_credit_limit', 'foreign_request', 'source',\n",
       "       'session_length_in_minutes', 'device_os', 'keep_alive_session',\n",
       "       'device_distinct_emails_8w', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_base.drop(columns=[\"device_fraud_count\"], inplace=True)\n",
    "df_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a56e5f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 31)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fe596",
   "metadata": {},
   "source": [
    "## Train, Test, Val split.\n",
    "\n",
    "We will divide the data in 3 splits using the month as an index for this division. We will first separate the categorical columns as they will have to be treated differently when fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd09e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns size: 24\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['device_os', 'employment_status', 'housing_status', 'payment_type', 'source']\n",
    "target_col = 'fraud_bool'\n",
    "index_col = 'month'\n",
    "num_cols = [c for c in df_base.columns if c not in categorical_cols + [target_col, index_col]]\n",
    "print(f\"Numerical columns size: {len(num_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55f85483",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_base[df_base[index_col].between(0, 4)].copy()\n",
    "val_df   = df_base[df_base[index_col].between(5, 6)].copy()\n",
    "test_df  = df_base[df_base[index_col] == 7].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68129a17",
   "metadata": {},
   "source": [
    "Encoding categorical columns and scaling numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c47482d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we generate a new encoder for each categorical column\n",
    "# and we save it in a dictionary to be used later if needed.\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    val_df[col]   = val_df[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "    test_df[col]  = test_df[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "    encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cc7ef",
   "metadata": {},
   "source": [
    "In the dataset negative values are used to indicate missing values. We will replace them with Nan and then impute them with the median of each column. We will also add a column that indicates if the value was missing or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95aa6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, val_df, test_df]:\n",
    "    df[num_cols] = df[num_cols].mask(df[num_cols] < 0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1046f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the median because it is more robust to outliers ans we keep the outliers because we want to detect an outlier (fraud).\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50742da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit only on training data\n",
    "train_df_num = num_pipeline.fit_transform(train_df[num_cols])\n",
    "\n",
    "# Transform val/test\n",
    "val_df_num = num_pipeline.transform(val_df[num_cols])\n",
    "test_df_num = num_pipeline.transform(test_df[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8eb491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income',\n",
       " 'name_email_similarity',\n",
       " 'prev_address_months_count',\n",
       " 'current_address_months_count',\n",
       " 'customer_age',\n",
       " 'days_since_request',\n",
       " 'intended_balcon_amount',\n",
       " 'zip_count_4w',\n",
       " 'velocity_6h',\n",
       " 'velocity_24h',\n",
       " 'velocity_4w',\n",
       " 'bank_branch_count_8w',\n",
       " 'date_of_birth_distinct_emails_4w',\n",
       " 'credit_risk_score',\n",
       " 'email_is_free',\n",
       " 'phone_home_valid',\n",
       " 'phone_mobile_valid',\n",
       " 'bank_months_count',\n",
       " 'has_other_cards',\n",
       " 'proposed_credit_limit',\n",
       " 'foreign_request',\n",
       " 'session_length_in_minutes',\n",
       " 'keep_alive_session',\n",
       " 'device_distinct_emails_8w',\n",
       " 'missingindicator_prev_address_months_count',\n",
       " 'missingindicator_current_address_months_count',\n",
       " 'missingindicator_intended_balcon_amount',\n",
       " 'missingindicator_velocity_6h',\n",
       " 'missingindicator_credit_risk_score',\n",
       " 'missingindicator_bank_months_count',\n",
       " 'missingindicator_session_length_in_minutes',\n",
       " 'missingindicator_device_distinct_emails_8w']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the final column names from the fitted pipeline\n",
    "all_num_cols = num_pipeline.named_steps[\"imputer\"].get_feature_names_out(num_cols).tolist()\n",
    "all_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c249fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace numerical data in DataFrames\n",
    "train_df = pd.concat([\n",
    "    pd.DataFrame(train_df_num, columns=all_num_cols, index=train_df.index),\n",
    "    train_df[categorical_cols + [target_col]]\n",
    "], axis=1)\n",
    "\n",
    "val_df = pd.concat([\n",
    "    pd.DataFrame(val_df_num, columns=all_num_cols, index=val_df.index),\n",
    "    val_df[categorical_cols + [target_col]]\n",
    "], axis=1)\n",
    "\n",
    "test_df = pd.concat([\n",
    "    pd.DataFrame(test_df_num, columns=all_num_cols, index=test_df.index),\n",
    "    test_df[categorical_cols + [target_col]]\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be386d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "name_email_similarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prev_address_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "current_address_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "customer_age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "days_since_request",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "intended_balcon_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "zip_count_4w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "velocity_6h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "velocity_24h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "velocity_4w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bank_branch_count_8w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_of_birth_distinct_emails_4w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "credit_risk_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "email_is_free",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "phone_home_valid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "phone_mobile_valid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bank_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_other_cards",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "proposed_credit_limit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "foreign_request",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "session_length_in_minutes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "keep_alive_session",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "device_distinct_emails_8w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_prev_address_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_current_address_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_intended_balcon_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_velocity_6h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_credit_risk_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_bank_months_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_session_length_in_minutes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "missingindicator_device_distinct_emails_8w",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "device_os",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "employment_status",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "housing_status",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "payment_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fraud_bool",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cd9c9ed0-af36-4dcd-ac18-9ac794ce2374",
       "rows": [
        [
         "0",
         "0.25",
         "0.9865069642778407",
         "0.07258064516129033",
         "0.0588235294117647",
         "0.375",
         "8.79505500985247e-05",
         "0.9070155873155042",
         "0.1579340200029855",
         "0.7834550424813486",
         "0.7963201026081557",
         "0.937131236904921",
         "0.0020999580008399833",
         "0.1282051282051282",
         "0.4190231362467866",
         "1.0",
         "0.0",
         "1.0",
         "0.25806451612903225",
         "0.0",
         "0.6858638743455497",
         "0.0",
         "0.18885167626821225",
         "1.0",
         "0.5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "1",
         "2",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "0.875",
         "0.6174258786549277",
         "0.07258064516129033",
         "0.20941176470588233",
         "0.125",
         "0.00013182161294069666",
         "0.2873706991376263",
         "0.24735035079862663",
         "0.551760668182047",
         "0.5373197362522502",
         "0.7379844097025832",
         "0.00125997480050399",
         "0.4615384615384615",
         "0.3958868894601542",
         "1.0",
         "1.0",
         "1.0",
         "0.03225806451612903",
         "0.0",
         "0.6858638743455497",
         "0.0",
         "0.03912401066195392",
         "1.0",
         "0.5",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "0",
         "2",
         "3",
         "0",
         "0"
        ],
        [
         "2",
         "0.875",
         "0.9967076958781975",
         "0.010752688172043012",
         "0.03294117647058823",
         "0.375",
         "0.0001608266899986131",
         "0.2873706991376263",
         "0.16330795641140466",
         "0.2674749563456562",
         "0.5037085974654455",
         "0.7506461212036124",
         "0.00629987400251995",
         "0.28205128205128205",
         "0.2287917737789203",
         "1.0",
         "0.0",
         "1.0",
         "0.935483870967742",
         "0.0",
         "0.005235602094240843",
         "0.0",
         "0.26459123138272306",
         "0.0",
         "0.5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "3",
         "0",
         "2",
         "1",
         "0",
         "0"
        ],
        [
         "3",
         "0.6250000000000001",
         "0.475099517357662",
         "0.016129032258064516",
         "0.03294117647058823",
         "0.25",
         "9.128612886736264e-05",
         "0.2873706991376263",
         "0.5197790715032095",
         "0.8633811842996706",
         "0.6615606150906251",
         "0.7451181180651412",
         "0.004619907601847963",
         "0.3333333333333333",
         "0.2313624678663239",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.005235602094240843",
         "0.0",
         "0.17710457847909003",
         "1.0",
         "0.5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "2",
         "1",
         "0",
         "0"
        ],
        [
         "4",
         "1.0",
         "0.8423071854228267",
         "0.07258064516129033",
         "0.06823529411764705",
         "0.375",
         "0.07498713860787172",
         "0.4174369243663987",
         "0.3490073145245559",
         "0.4547352313721388",
         "0.46091192087292165",
         "0.7377528607216266",
         "0.00041999160016799666",
         "0.15384615384615385",
         "0.2339331619537275",
         "0.0",
         "1.0",
         "1.0",
         "0.8064516129032258",
         "0.0",
         "0.005235602094240843",
         "0.0",
         "0.043538590426451015",
         "0.0",
         "0.5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2",
         "0",
         "2",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>missingindicator_credit_risk_score</th>\n",
       "      <th>missingindicator_bank_months_count</th>\n",
       "      <th>missingindicator_session_length_in_minutes</th>\n",
       "      <th>missingindicator_device_distinct_emails_8w</th>\n",
       "      <th>device_os</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>source</th>\n",
       "      <th>fraud_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.907016</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.783455</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.287371</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.551761</td>\n",
       "      <td>0.537320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.287371</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.267475</td>\n",
       "      <td>0.503709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.287371</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.863381</td>\n",
       "      <td>0.661561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.068235</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.074987</td>\n",
       "      <td>0.417437</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.454735</td>\n",
       "      <td>0.460912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  name_email_similarity  prev_address_months_count  \\\n",
       "0   0.250               0.986507                   0.072581   \n",
       "1   0.875               0.617426                   0.072581   \n",
       "2   0.875               0.996708                   0.010753   \n",
       "3   0.625               0.475100                   0.016129   \n",
       "4   1.000               0.842307                   0.072581   \n",
       "\n",
       "   current_address_months_count  customer_age  days_since_request  \\\n",
       "0                      0.058824         0.375            0.000088   \n",
       "1                      0.209412         0.125            0.000132   \n",
       "2                      0.032941         0.375            0.000161   \n",
       "3                      0.032941         0.250            0.000091   \n",
       "4                      0.068235         0.375            0.074987   \n",
       "\n",
       "   intended_balcon_amount  zip_count_4w  velocity_6h  velocity_24h  ...  \\\n",
       "0                0.907016      0.157934     0.783455      0.796320  ...   \n",
       "1                0.287371      0.247350     0.551761      0.537320  ...   \n",
       "2                0.287371      0.163308     0.267475      0.503709  ...   \n",
       "3                0.287371      0.519779     0.863381      0.661561  ...   \n",
       "4                0.417437      0.349007     0.454735      0.460912  ...   \n",
       "\n",
       "   missingindicator_credit_risk_score  missingindicator_bank_months_count  \\\n",
       "0                                 0.0                                 0.0   \n",
       "1                                 0.0                                 0.0   \n",
       "2                                 0.0                                 0.0   \n",
       "3                                 0.0                                 0.0   \n",
       "4                                 0.0                                 0.0   \n",
       "\n",
       "   missingindicator_session_length_in_minutes  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   missingindicator_device_distinct_emails_8w  device_os  employment_status  \\\n",
       "0                                         0.0          0                  1   \n",
       "1                                         0.0          2                  0   \n",
       "2                                         0.0          3                  0   \n",
       "3                                         0.0          0                  0   \n",
       "4                                         0.0          2                  0   \n",
       "\n",
       "   housing_status  payment_type  source  fraud_bool  \n",
       "0               2             0       0           0  \n",
       "1               2             3       0           0  \n",
       "2               2             1       0           0  \n",
       "3               2             1       0           0  \n",
       "4               2             0       0           0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87abeba",
   "metadata": {},
   "source": [
    "## Extracting the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b67b8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(paths.PROCESSED_DATA_DIR / \"train.parquet\", index=False)\n",
    "val_df.to_parquet(paths.PROCESSED_DATA_DIR / \"val.parquet\", index=False)\n",
    "test_df.to_parquet(paths.PROCESSED_DATA_DIR / \"test.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e97229",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb4ce7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\gonca\\\\OneDrive\\\\Ambiente de Trabalho\\\\MECD\\\\Ano_2\\\\Semestre1\\\\ACED\\\\AECD.Feedzai-Benchmarking-optimizers-and-learning-rate-schedulers\\\\data\\\\processed\\\\num_pipeline.joblib']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we want we can save the encoders and the imputing pipeline for later use\n",
    "joblib.dump(encoders, paths.PROCESSED_DATA_DIR / \"label_encoders.joblib\")\n",
    "joblib.dump(num_pipeline, paths.PROCESSED_DATA_DIR / \"num_pipeline.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final numerical columns: 32\n"
     ]
    }
   ],
   "source": [
    "# to then load up our splits we can add this code to beggining of any script were we need the data\n",
    "# ============================================================\n",
    "# Load preprocessed data splits and preprocessing objects\n",
    "# ============================================================\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Path setup\n",
    "DATA_DIR = paths.PROCESSED_DATA_DIR  # assuming you have this imported somewhere\n",
    "train_df = pd.read_parquet(DATA_DIR / \"train.parquet\")\n",
    "val_df   = pd.read_parquet(DATA_DIR / \"val.parquet\")\n",
    "test_df  = pd.read_parquet(DATA_DIR / \"test.parquet\")\n",
    "\n",
    "# Load preprocessing artifacts (encoders + numeric pipeline)\n",
    "encoders = joblib.load(DATA_DIR / \"label_encoders.joblib\")\n",
    "num_pipeline = joblib.load(DATA_DIR / \"num_pipeline.joblib\")  # <- instead of scaler only\n",
    "\n",
    "# ============================================================\n",
    "# Define columns\n",
    "# ============================================================\n",
    "categorical_cols = ['device_os', 'employment_status', 'housing_status', 'payment_type', 'source']\n",
    "target_col = 'fraud_bool'\n",
    "\n",
    "# The numeric columns after preprocessing (imputer + indicators)\n",
    "num_cols = [c for c in train_df.columns if c not in categorical_cols + [target_col]]\n",
    "\n",
    "print(f\"Final numerical columns: {len(num_cols)}\")\n",
    "\n",
    "# ============================================================\n",
    "# Convert to tensors\n",
    "# ============================================================\n",
    "X_train_cont = torch.tensor(train_df[num_cols].values, dtype=torch.float32)\n",
    "X_train_cat  = torch.tensor(train_df[categorical_cols].values, dtype=torch.long)\n",
    "y_train      = torch.tensor(train_df[target_col].values, dtype=torch.float32)\n",
    "\n",
    "X_val_cont = torch.tensor(val_df[num_cols].values, dtype=torch.float32)\n",
    "X_val_cat  = torch.tensor(val_df[categorical_cols].values, dtype=torch.long)\n",
    "y_val      = torch.tensor(val_df[target_col].values, dtype=torch.float32)\n",
    "\n",
    "X_test_cont = torch.tensor(test_df[num_cols].values, dtype=torch.float32)\n",
    "X_test_cat  = torch.tensor(test_df[categorical_cols].values, dtype=torch.long)\n",
    "y_test      = torch.tensor(test_df[target_col].values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88cefc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675666, 32]), torch.Size([675666, 5]), torch.Size([675666]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cont.shape, X_train_cat.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c057426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import joblib, pandas as pd\\n\\nencoders = joblib.load(paths.PROCESSED_DATA_DIR / \"label_encoders.joblib\")\\nnum_pipeline = joblib.load(paths.PROCESSED_DATA_DIR / \"num_pipeline.joblib\")\\n\\n# Preprocess new data\\nnew_df = raw_data.copy()\\n\\n# Encode categoricals\\nfor col, le in encoders.items():\\n    new_df[col] = new_df[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\\n\\n# Handle numerical part (convert negatives to NaN)\\nnum_cols = [c for c in new_df.columns if c not in categorical_cols + [target_col, index_col]]\\nnew_df[num_cols] = new_df[num_cols].mask(new_df[num_cols] < 0, np.nan)\\n\\n# Apply fitted pipeline\\nnew_df_num = num_pipeline.transform(new_df[num_cols])'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if one would want to infere on raw data, the following code could be used:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def preprocess_for_inference(raw_df, encoders, num_pipeline, categorical_cols, target_col=None, index_col=None):\n",
    "    \"\"\"\n",
    "    Preprocess raw input data for inference with a model trained on encoded and scaled features.\n",
    "    Applies the same transformations as during training:\n",
    "    - Encodes categorical variables using fitted LabelEncoders.\n",
    "    - Replaces negative values in numeric columns with NaN.\n",
    "    - Applies the fitted numeric pipeline (imputation + scaling + missing indicators).\n",
    "    - Combines numerical and categorical features.\n",
    "    - Converts the final arrays to PyTorch tensors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_df : pd.DataFrame\n",
    "        Input data before preprocessing.\n",
    "    encoders : dict\n",
    "        Dictionary of fitted LabelEncoders for categorical columns.\n",
    "    num_pipeline : sklearn.pipeline.Pipeline\n",
    "        Fitted pipeline for numeric data (imputer + scaler).\n",
    "    categorical_cols : list of str\n",
    "        Names of categorical columns.\n",
    "    target_col : str or None\n",
    "        Optional; target column name, if available.\n",
    "    index_col : str or None\n",
    "        Optional; column to drop if present (e.g., time/month index).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_cont : torch.Tensor\n",
    "        Continuous (numeric) features.\n",
    "    X_cat : torch.Tensor\n",
    "        Categorical features.\n",
    "    y_true : torch.Tensor or None\n",
    "        Target tensor if present, otherwise None.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = raw_df.copy()\n",
    "    \n",
    "    # Drop index column if specified\n",
    "    if index_col and index_col in df.columns:\n",
    "        df = df.drop(columns=[index_col])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col, le in encoders.items():\n",
    "        df[col] = df[col].map(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    num_cols = [c for c in df.columns if c not in categorical_cols + ([target_col] if target_col else [])]\n",
    "    \n",
    "    # Replace negative values (missing indicators) with NaN\n",
    "    df[num_cols] = df[num_cols].mask(df[num_cols] < 0, np.nan)\n",
    "    \n",
    "    # Apply the fitted numeric pipeline\n",
    "    num_transformed = num_pipeline.transform(df[num_cols])\n",
    "    all_num_cols = num_pipeline.named_steps[\"imputer\"].get_feature_names_out(num_cols)\n",
    "    df_num = pd.DataFrame(num_transformed, columns=all_num_cols, index=df.index)\n",
    "    \n",
    "    # Combine numerical and categorical features\n",
    "    processed_df = pd.concat([df_num, df[categorical_cols]], axis=1)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_cont = torch.tensor(processed_df[all_num_cols].values, dtype=torch.float32)\n",
    "    X_cat = torch.tensor(processed_df[categorical_cols].values, dtype=torch.long)\n",
    "    \n",
    "    # Handle target column if present\n",
    "    y_true = None\n",
    "    if target_col and target_col in df.columns:\n",
    "        y_true = torch.tensor(df[target_col].values, dtype=torch.float32)\n",
    "    \n",
    "    return X_cont, X_cat, y_true\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
